# AI-Powered Customer Journey Orchestration Templates

## Overview
This document provides practical templates for designing and implementing autonomous, AI-driven customer journeys. Each template includes decision logic, channel strategies, personalization rules, and success metrics.

## Journey Design Framework

### Components of an AI-Powered Journey

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  JOURNEY ARCHITECTURE                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  [ENTRY CRITERIA] â†’ [AI DECISION ENGINE] â†’ [ACTION]     â”‚
â”‚         â†“                    â†“                  â†“        â”‚
â”‚   User Behavior      Next Best Action      Channel       â”‚
â”‚   User Profile       Optimal Timing         Content      â”‚
â”‚   Lifecycle Stage    Priority Score         Offer        â”‚
â”‚                                                          â”‚
â”‚  [MEASURE] â†’ [LEARN] â†’ [OPTIMIZE]                       â”‚
â”‚       â†“          â†“          â†“                            â”‚
â”‚   Engagement  Update AI  Adjust Journey                  â”‚
â”‚   Conversion   Model     Parameters                      â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Journey Metadata Template

```yaml
journey_name: "[Journey Name]"
journey_id: "[unique_id]"
journey_type: "[onboarding|nurture|retention|upsell|reactivation]"
target_audience: "[Audience description]"
business_objective: "[Primary goal]"
success_metrics:
  primary: "[Main KPI]"
  secondary: "[Supporting KPIs]"
channels: ["email", "sms", "push", "in-app", "web", "ads"]
average_duration: "[Expected journey length]"
ai_decision_points: "[Number of AI-driven decisions]"
status: "[draft|active|paused|archived]"
```

---

## Template 1: New Customer Onboarding Journey

### Journey Metadata

```yaml
journey_name: "SaaS New Customer Onboarding"
journey_id: "journey_onboarding_v2"
journey_type: "onboarding"
target_audience: "Customers who signed up within last 24 hours"
business_objective: "Activate users and drive feature adoption within 30 days"
success_metrics:
  primary: "% of customers who complete core workflow within 30 days"
  secondary:
    - "Time to first value (TTFV)"
    - "Feature adoption rate"
    - "30-day retention"
channels: ["email", "in-app", "push"]
average_duration: "30 days"
ai_decision_points: 8
status: "active"
```

### Entry Criteria

```sql
-- Trigger: Customer signs up and completes initial setup
SELECT user_id
FROM events
WHERE event_name = 'account_created'
  AND event_timestamp >= CURRENT_TIMESTAMP() - INTERVAL 24 HOUR
  AND user_id NOT IN (
    SELECT user_id FROM journeys.onboarding_enrolled
  )
```

### Journey Map

```
Day 0 (Sign-Up)
  â”œâ”€ [IMMEDIATE] Welcome Email
  â”‚   â””â”€ AI Decision: Personalize based on signup source
  â”‚       â”œâ”€ If organic search â†’ Focus on problem-solving
  â”‚       â”œâ”€ If paid ad â†’ Reference specific campaign promise
  â”‚       â””â”€ If referral â†’ Mention referrer, social proof
  â”‚
  â”œâ”€ [IMMEDIATE] In-App Welcome Tour
  â”‚   â””â”€ AI Decision: Customize tour based on role
  â”‚       â”œâ”€ If "Analyst" â†’ Data visualization features
  â”‚       â”œâ”€ If "Manager" â†’ Dashboard and reporting
  â”‚       â””â”€ If "Admin" â†’ Setup and permissions
  â”‚
Day 1
  â”œâ”€ [AI DECISION POINT #1] Next Best Action
  â”‚   â””â”€ IF user completed core workflow Day 0
  â”‚       â”œâ”€ Send "Great Start!" email with advanced tips
  â”‚       â””â”€ Show in-app message: "Ready for step 2?"
  â”‚   â””â”€ ELSE (no activity)
  â”‚       â”œâ”€ Send "Getting Started Guide" email
  â”‚       â””â”€ Push notification: "Complete your first analysis in 5 minutes"
  â”‚
Day 3
  â”œâ”€ [AI DECISION POINT #2] Engagement Check
  â”‚   â””â”€ Calculate Engagement Score (0-100)
  â”‚       Formula: (logins * 10) + (features_used * 5) + (workflow_completed * 20)
  â”‚   â””â”€ IF Engagement Score > 50 (High Engagement)
  â”‚       â”œâ”€ Email: "You're Doing Great! Here's What's Next"
  â”‚       â””â”€ Offer: Invite to advanced webinar
  â”‚   â””â”€ ELSE IF Engagement Score 20-50 (Medium)
  â”‚       â”œâ”€ Email: "Quick Tips to Get More Value"
  â”‚       â””â”€ In-app: Show video tutorial
  â”‚   â””â”€ ELSE (Low Engagement <20)
  â”‚       â”œâ”€ Email: "Need Help Getting Started?"
  â”‚       â””â”€ Offer: Schedule 1:1 onboarding call with CSM
  â”‚
Day 7 (Week 1 Check-In)
  â”œâ”€ [AI DECISION POINT #3] Feature Adoption Analysis
  â”‚   â””â”€ Predict: Which feature should user learn next?
  â”‚       Model: Collaborative filtering (users like you used X next)
  â”‚   â””â”€ Send personalized "Feature Spotlight" email
  â”‚   â””â”€ In-app tooltip highlighting recommended feature
  â”‚
Day 14 (Week 2 Milestone)
  â”œâ”€ [AI DECISION POINT #4] Progress Assessment
  â”‚   â””â”€ IF core workflow completed
  â”‚       â”œâ”€ Email: "You're Officially Activated! ðŸŽ‰"
  â”‚       â”œâ”€ Request review/testimonial
  â”‚       â””â”€ Exit onboarding journey â†’ Enter "Active User Nurture"
  â”‚   â””â”€ ELSE
  â”‚       â”œâ”€ Calculate Churn Risk (predictive model)
  â”‚       â”œâ”€ IF Churn Risk > 60%
  â”‚       â”‚   â””â”€ Human intervention: CSM outreach call
  â”‚       â””â”€ ELSE
  â”‚           â””â”€ Continue automated journey
  â”‚
Day 21
  â”œâ”€ [AI DECISION POINT #5] Upsell Readiness
  â”‚   â””â”€ Predict: Likelihood to upgrade (based on usage patterns)
  â”‚   â””â”€ IF Likelihood > 70% AND on starter plan
  â”‚       â”œâ”€ Email: "Ready to unlock advanced features?"
  â”‚       â”œâ”€ Offer: Limited-time upgrade discount
  â”‚       â””â”€ In-app: Show upgrade CTA on feature boundaries
  â”‚   â””â”€ ELSE
  â”‚       â””â”€ Continue feature education
  â”‚
Day 30 (End of Onboarding)
  â”œâ”€ [AI DECISION POINT #6] Journey Completion & Next Path
  â”‚   â””â”€ Calculate Overall Onboarding Success Score
  â”‚   â””â”€ IF Success Score > 75 (Highly Activated)
  â”‚       â”œâ”€ Email: "You're a Power User!"
  â”‚       â”œâ”€ Invite to customer advisory board
  â”‚       â””â”€ Transition to: "Power User Engagement Journey"
  â”‚   â””â”€ ELSE IF Success Score 40-75 (Moderately Activated)
  â”‚       â””â”€ Transition to: "Feature Adoption Journey"
  â”‚   â””â”€ ELSE (Poorly Activated <40)
  â”‚       â””â”€ Transition to: "At-Risk User Retention Journey"
```

### AI Decision Logic (Detailed)

**AI Decision Point #2: Engagement Check**

```python
def calculate_engagement_score(user_id, days_since_signup=3):
    """Calculate user engagement score for decision-making"""

    # Fetch user activity from BigQuery
    query = f"""
    SELECT
      COUNT(DISTINCT date) AS login_days,
      COUNT(DISTINCT feature_used) AS features_used,
      COUNTIF(event_name = 'core_workflow_completed') AS workflows_completed,
      MAX(session_duration_minutes) AS max_session_duration
    FROM events
    WHERE user_id = '{user_id}'
      AND DATE(event_timestamp) BETWEEN
        DATE_SUB(CURRENT_DATE(), INTERVAL {days_since_signup} DAY) AND CURRENT_DATE()
    """

    result = bigquery_client.query(query).to_dataframe().iloc[0]

    # Calculate weighted engagement score
    score = (
        result['login_days'] * 10 +
        result['features_used'] * 5 +
        result['workflows_completed'] * 20 +
        min(result['max_session_duration'], 30)  # Cap at 30 points
    )

    # Normalize to 0-100
    score = min(score, 100)

    return {
        'score': score,
        'tier': 'high' if score > 50 else 'medium' if score > 20 else 'low',
        'login_days': result['login_days'],
        'features_used': result['features_used'],
        'workflows_completed': result['workflows_completed']
    }

def determine_next_action(engagement_data):
    """Determine next best action based on engagement"""

    if engagement_data['tier'] == 'high':
        return {
            'action': 'send_email',
            'template': 'onboarding_high_engagement',
            'subject': "You're Doing Great! Here's What's Next",
            'send_time': 'optimal',  # AI-predicted best time
            'secondary_action': {
                'action': 'show_in_app',
                'message': 'advanced_webinar_invite'
            }
        }
    elif engagement_data['tier'] == 'medium':
        return {
            'action': 'send_email',
            'template': 'onboarding_medium_engagement',
            'subject': 'Quick Tips to Get More Value',
            'send_time': 'optimal',
            'secondary_action': {
                'action': 'show_in_app',
                'message': 'tutorial_video_prompt'
            }
        }
    else:  # low engagement
        return {
            'action': 'send_email',
            'template': 'onboarding_low_engagement',
            'subject': 'Need Help Getting Started?',
            'send_time': 'morning',  # More likely to be read
            'offer': {
                'type': 'csm_call',
                'urgency': 'high',
                'calendar_link': generate_csm_calendar_link(user_id)
            },
            'secondary_action': {
                'action': 'push_notification',
                'message': 'We\'re here to help! Book a quick call.',
                'delay_hours': 2
            }
        }
```

### Measurement & Optimization

**Journey Performance Dashboard**

```sql
-- Onboarding Journey Performance
WITH journey_users AS (
  SELECT
    user_id,
    journey_entry_date,
    DATE_DIFF(CURRENT_DATE(), journey_entry_date, DAY) AS days_in_journey
  FROM journeys.onboarding_enrolled
  WHERE journey_entry_date >= '2025-01-01'
),

completion_metrics AS (
  SELECT
    ju.user_id,
    MAX(CASE WHEN e.event_name = 'core_workflow_completed' THEN 1 ELSE 0 END) AS completed_workflow,
    MIN(CASE WHEN e.event_name = 'core_workflow_completed'
        THEN DATE_DIFF(e.event_date, ju.journey_entry_date, DAY) END) AS days_to_completion,
    COUNT(DISTINCT e.feature_used) AS total_features_used
  FROM journey_users ju
  LEFT JOIN events e ON ju.user_id = e.user_id
    AND e.event_date >= ju.journey_entry_date
  GROUP BY ju.user_id
)

SELECT
  -- Overall Metrics
  COUNT(*) AS total_users,
  COUNTIF(completed_workflow = 1) AS users_completed,
  SAFE_DIVIDE(COUNTIF(completed_workflow = 1), COUNT(*)) AS completion_rate,

  -- Time to Value
  AVG(days_to_completion) AS avg_days_to_completion,
  APPROX_QUANTILES(days_to_completion, 100)[OFFSET(50)] AS median_days_to_completion,

  -- Engagement
  AVG(total_features_used) AS avg_features_used,

  -- Retention (30-day)
  COUNTIF(days_in_journey >= 30 AND last_active_date >= CURRENT_DATE() - 7) AS retained_30_day,
  SAFE_DIVIDE(
    COUNTIF(days_in_journey >= 30 AND last_active_date >= CURRENT_DATE() - 7),
    COUNTIF(days_in_journey >= 30)
  ) AS retention_rate_30_day

FROM journey_users ju
JOIN completion_metrics cm ON ju.user_id = cm.user_id
```

**A/B Testing Framework**

```python
# Test different journey variations
def create_journey_variant(variant_name, changes):
    """
    Create a journey variant for A/B testing

    Example changes:
    {
        "day_3_timing": "morning",  # vs "optimal"
        "low_engagement_action": "csm_call",  # vs "tutorial_video"
        "email_frequency": "high"  # vs "medium"
    }
    """

    base_journey = load_journey_template("onboarding_v2")

    # Apply changes
    variant_journey = base_journey.copy()
    for key, value in changes.items():
        variant_journey[key] = value

    variant_journey['variant_name'] = variant_name
    variant_journey['variant_traffic'] = 0.2  # 20% of traffic

    return variant_journey

# Deploy A/B test
variants = [
    create_journey_variant("control", {}),  # No changes
    create_journey_variant("aggressive_csm", {
        "day_3_low_engagement_action": "csm_call_immediate",
        "csm_call_threshold": 30  # Lower threshold
    }),
    create_journey_variant("video_first", {
        "day_1_action": "video_tutorial",
        "day_3_medium_engagement_action": "advanced_video"
    })
]

# Monitor and declare winner after 500 users per variant
monitor_ab_test(variants, sample_size=500, primary_metric="completion_rate")
```

---

## Template 2: Churn Prevention / Retention Journey

### Journey Metadata

```yaml
journey_name: "At-Risk Customer Retention"
journey_id: "journey_churn_prevention_v1"
journey_type: "retention"
target_audience: "Customers with churn risk score > 60%"
business_objective: "Reduce churn by 30% through proactive engagement"
success_metrics:
  primary: "Churn rate reduction (% retained)"
  secondary:
    - "Re-engagement rate (usage increase)"
    - "Support ticket resolution rate"
    - "NPS score improvement"
channels: ["email", "sms", "phone", "in-app"]
average_duration: "14-21 days"
ai_decision_points: 5
status: "active"
```

### Entry Criteria

```sql
-- Triggered by daily churn prediction model
SELECT
  user_id,
  churn_probability,
  churn_risk_tier,
  primary_risk_factors  -- e.g., ["declining_usage", "support_tickets", "payment_issues"]
FROM marts.churn_predictions
WHERE churn_probability > 0.60
  AND churn_risk_tier IN ('high', 'critical')
  AND user_id NOT IN (
    SELECT user_id FROM journeys.churn_prevention_enrolled
    WHERE entry_date >= CURRENT_DATE() - 30  -- Don't re-enter within 30 days
  )
```

### Journey Map

```
Day 0 (Entry: Churn Risk Detected)
  â”œâ”€ [IMMEDIATE] AI Analysis: Identify Root Cause
  â”‚   â””â”€ Analyze primary_risk_factors
  â”‚       â”œâ”€ "declining_usage" â†’ Feature education path
  â”‚       â”œâ”€ "support_tickets" â†’ Priority support path
  â”‚       â”œâ”€ "payment_issues" â†’ Billing assistance path
  â”‚       â”œâ”€ "competitor_research" â†’ Value reinforcement path
  â”‚       â””â”€ "price_sensitivity" â†’ Discount/value path
  â”‚
  â”œâ”€ [IMMEDIATE] Personalized Outreach
  â”‚   â””â”€ Channel Selection (AI-predicted best channel)
  â”‚       â”œâ”€ High-value customer (CLV > $10k) â†’ CSM phone call
  â”‚       â”œâ”€ Medium-value â†’ Personalized email from account manager
  â”‚       â””â”€ Lower-value â†’ Automated email with self-service resources
  â”‚
  â”‚   â””â”€ Message Personalization
  â”‚       Template: "Hi {{first_name}}, I noticed {{risk_factor_statement}}.
  â”‚                 I want to make sure you're getting the most value..."
  â”‚
Day 2 (Follow-Up)
  â”œâ”€ [AI DECISION POINT #1] Response Analysis
  â”‚   â””â”€ IF customer engaged (email open, call answered, in-app action)
  â”‚       â”œâ”€ Provide tailored solution based on risk factor
  â”‚       â”‚   â”œâ”€ Usage decline â†’ Tutorial + feature spotlight
  â”‚       â”‚   â”œâ”€ Support issues â†’ Escalate to senior support + knowledge base
  â”‚       â”‚   â””â”€ Price â†’ Special offer (if authorized)
  â”‚       â””â”€ Continue monitoring
  â”‚   â””â”€ ELSE (No response)
  â”‚       â”œâ”€ Try alternate channel (email â†’ SMS or in-app message)
  â”‚       â””â”€ Increase urgency slightly
  â”‚
Day 5 (Mid-Journey Check)
  â”œâ”€ [AI DECISION POINT #2] Progress Assessment
  â”‚   â””â”€ Recalculate churn risk score
  â”‚   â””â”€ IF risk decreased (usage increased, issue resolved)
  â”‚       â”œâ”€ Send positive reinforcement message
  â”‚       â””â”€ Transition to "Active User Nurture" journey
  â”‚   â””â”€ ELSE IF risk same or increased
  â”‚       â”œâ”€ Escalate: Human intervention required
  â”‚       â”œâ”€ CSM outreach (regardless of CLV)
  â”‚       â””â”€ Offer: "We value your business" retention offer
  â”‚
Day 10 (Final Push)
  â”œâ”€ [AI DECISION POINT #3] Last Opportunity
  â”‚   â””â”€ IF still at high risk and no engagement
  â”‚       â”œâ”€ Executive outreach (email from VP Customer Success)
  â”‚       â”œâ”€ Offer: Significant discount or free upgrade for 3 months
  â”‚       â”œâ”€ "Winback" survey: "What would it take to keep you?"
  â”‚       â””â”€ Set reminder for manual review in 5 days
  â”‚   â””â”€ ELSE (some engagement)
  â”‚       â””â”€ Continue nurture with weekly check-ins
  â”‚
Day 14-21 (Journey Exit)
  â”œâ”€ [AI DECISION POINT #4] Outcome Determination
  â”‚   â””â”€ Recalculate final churn risk score
  â”‚   â””â”€ IF risk < 40% (Successfully retained)
  â”‚       â”œâ”€ Mark journey as "Success"
  â”‚       â”œâ”€ Send "Glad You're Still With Us" message
  â”‚       â””â”€ Transition to standard customer journey
  â”‚   â””â”€ ELSE IF risk 40-60% (Partially retained)
  â”‚       â”œâ”€ Keep in journey, extend to 30 days
  â”‚       â”œâ”€ Monthly CSM check-ins
  â”‚   â””â”€ ELSE (High risk persists >60%)
  â”‚       â”œâ”€ Mark journey as "Unsuccessful - High Risk"
  â”‚       â”œâ”€ Final retention offer (human decision)
  â”‚       â”œâ”€ Prepare for likely churn
  â”‚       â””â”€ Transition to "Winback Journey" after churn
```

### Retention Offer Decision Tree

```python
def determine_retention_offer(user_data):
    """
    AI-powered decision on what retention offer to make
    Balances: retention probability increase vs. offer cost
    """

    # Load retention offer effectiveness model (trained on historical data)
    model = load_model("retention_offer_effectiveness")

    # Candidate offers
    offers = [
        {"type": "discount_20_percent", "cost": user_data['mrr'] * 0.20 * 3, "duration_months": 3},
        {"type": "free_upgrade", "cost": 50 * 3, "duration_months": 3},
        {"type": "premium_support", "cost": 100, "duration_months": 1},
        {"type": "custom_training", "cost": 500, "duration_months": 0},
        {"type": "no_offer", "cost": 0, "duration_months": 0}
    ]

    # Predict retention probability increase for each offer
    offer_predictions = []
    for offer in offers:
        features = {
            "churn_risk": user_data['churn_probability'],
            "clv": user_data['clv'],
            "offer_type": offer['type'],
            "offer_value": offer['cost'],
            "tenure_months": user_data['tenure_months'],
            "risk_factors": user_data['primary_risk_factors']
        }

        # Predict: P(retain | offer) - P(retain | no offer)
        retention_lift = model.predict_retention_lift(features)

        # Calculate expected value
        expected_value = (retention_lift * user_data['clv']) - offer['cost']

        offer_predictions.append({
            **offer,
            "retention_lift": retention_lift,
            "expected_value": expected_value
        })

    # Select offer with highest expected value (but must have positive EV)
    best_offer = max(offer_predictions, key=lambda x: x['expected_value'])

    if best_offer['expected_value'] > 0:
        return best_offer
    else:
        return {"type": "no_offer", "reason": "No offer has positive expected value"}
```

---

## Template 3: Free Trial to Paid Conversion Journey

### Journey Metadata

```yaml
journey_name: "Trial User Activation & Conversion"
journey_id: "journey_trial_conversion_v1"
journey_type: "nurture"
target_audience: "Users on 14-day free trial"
business_objective: "Convert 30%+ of trial users to paying customers"
success_metrics:
  primary: "Trial-to-paid conversion rate"
  secondary:
    - "Time to conversion (days)"
    - "Plan type selected (Starter vs Pro vs Enterprise)"
    - "Trial engagement score"
channels: ["email", "in-app", "sms", "retargeting ads"]
average_duration: "14 days"
ai_decision_points: 7
status: "active"
```

### Journey Map

```
Day 1 (Trial Start)
  â”œâ”€ Welcome & Setup
  â”‚   â””â”€ Personalized onboarding based on signup intent
  â”‚
Day 3 [AI DECISION #1: Early Engagement Signal]
  â”œâ”€ IF high engagement (3+ logins, core feature used)
  â”‚   â””â”€ Email: "You're crushing it! Here's what to explore next"
  â”œâ”€ ELSE
  â”‚   â””â”€ Email: "Getting started tips + quick-win tutorial"
  â”‚
Day 7 [AI DECISION #2: Midpoint Assessment]
  â”œâ”€ Predict conversion probability (model based on usage patterns)
  â”œâ”€ IF High probability (>60%)
  â”‚   â””â”€ Email: "Loving it? Convert now and save 20%"
  â”‚   â””â”€ Show in-app: Upgrade CTA with limited-time discount
  â”œâ”€ ELSE IF Medium (30-60%)
  â”‚   â””â”€ Email: "How can we help you get more value?"
  â”‚   â””â”€ Offer: Live demo with sales engineer
  â”œâ”€ ELSE (Low <30%)
  â”‚   â””â”€ Human intervention: SDR outreach call
  â”‚
Day 10 [AI DECISION #3: Urgency Injection]
  â”œâ”€ "Only 4 days left in your trial"
  â”œâ”€ Highlight: Features they've used + ROI they've gained
  â”œâ”€ Friction reduction: One-click upgrade button
  â”‚
Day 12 [AI DECISION #4: Final Push]
  â”œâ”€ IF haven't converted
  â”‚   â””â”€ Email: "Last chance - extend your trial or convert"
  â”‚   â””â”€ Offer: Option to extend trial by 7 days (if high engagement)
  â”‚
Day 14 [AI DECISION #5: Trial End]
  â”œâ”€ IF converted â†’ Celebration journey
  â”œâ”€ ELSE â†’ Post-trial winback journey (60-day nurture)
```

**Key Insight**: Use predictive scoring to identify high-intent users early and fast-track them to sales conversations.

---

## AI-Powered Channel Selection

### Multi-Channel Decision Logic

```python
def select_optimal_channel(user_id, message_urgency='medium'):
    """
    AI predicts which channel (email, SMS, push, in-app) will have highest engagement
    for this specific user for this type of message
    """

    # Get user's historical channel engagement
    query = f"""
    SELECT
      channel,
      COUNT(*) AS messages_sent,
      COUNTIF(opened = true) AS messages_opened,
      COUNTIF(clicked = true) AS messages_clicked,
      AVG(time_to_open_minutes) AS avg_time_to_open
    FROM communication_log
    WHERE user_id = '{user_id}'
      AND sent_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 90 DAY)
    GROUP BY channel
    """

    channel_history = bigquery_client.query(query).to_dataframe()

    # If no history, use global benchmarks
    if channel_history.empty:
        return {
            'channel': 'email',  # Default
            'reason': 'no_historical_data',
            'confidence': 0.5
        }

    # Calculate engagement rate by channel
    channel_history['engagement_rate'] = (
        channel_history['messages_clicked'] / channel_history['messages_sent']
    )

    # Adjust for message urgency
    if message_urgency == 'high':
        # Prefer faster channels
        channel_priority = {'sms': 1.5, 'push': 1.3, 'in-app': 1.2, 'email': 1.0}
    else:
        # No adjustment
        channel_priority = {'sms': 1.0, 'push': 1.0, 'in-app': 1.0, 'email': 1.0}

    channel_history['adjusted_score'] = (
        channel_history['engagement_rate'] * channel_history['channel'].map(channel_priority)
    )

    # Select channel with highest adjusted score
    best_channel = channel_history.loc[channel_history['adjusted_score'].idxmax()]

    return {
        'channel': best_channel['channel'],
        'expected_engagement_rate': best_channel['engagement_rate'],
        'confidence': min(best_channel['messages_sent'] / 20, 1.0),  # More data = higher confidence
        'fallback_channel': 'email'  # Always have a fallback
    }
```

---

## Journey Monitoring & Alerts

### Real-Time Journey Health Dashboard

```python
# Streamlit monitoring dashboard
import streamlit as st
import plotly.express as px

st.title("Customer Journey Performance Monitor")

# Select journey
journey_options = load_active_journeys()
selected_journey = st.selectbox("Select Journey", journey_options)

# Load metrics
metrics = get_journey_metrics(selected_journey, days=30)

# KPIs
col1, col2, col3, col4 = st.columns(4)

col1.metric(
    "Users in Journey",
    metrics['total_users'],
    delta=metrics['users_change_7d']
)

col2.metric(
    "Completion Rate",
    f"{metrics['completion_rate']:.1%}",
    delta=f"{metrics['completion_rate_change_7d']:.1%}"
)

col3.metric(
    "Avg. Time to Complete",
    f"{metrics['avg_days_to_complete']:.1f} days",
    delta=f"{metrics['days_change_7d']:.1f} days",
    delta_color="inverse"  # Lower is better
)

col4.metric(
    "Drop-off Rate",
    f"{metrics['dropoff_rate']:.1%}",
    delta=f"{metrics['dropoff_rate_change_7d']:.1%}",
    delta_color="inverse"  # Lower is better
)

# Funnel visualization
st.subheader("Journey Stage Funnel")
funnel_data = get_journey_funnel(selected_journey)
fig = px.funnel(funnel_data, x='users', y='stage', title="Conversion Funnel")
st.plotly_chart(fig)

# AI Decision Performance
st.subheader("AI Decision Point Analysis")
decision_perf = get_decision_point_performance(selected_journey)
st.dataframe(decision_perf)

# Alerts
st.subheader("âš ï¸ Active Alerts")
alerts = get_journey_alerts(selected_journey)
for alert in alerts:
    if alert['severity'] == 'critical':
        st.error(f"ðŸš¨ {alert['message']}")
    elif alert['severity'] == 'warning':
        st.warning(f"âš ï¸ {alert['message']}")
```

### Automated Alerts

```python
def check_journey_health(journey_id):
    """Run automated health checks and trigger alerts"""

    metrics = get_journey_metrics(journey_id, days=7)

    alerts = []

    # Alert 1: Drop-off rate spike
    if metrics['dropoff_rate'] > metrics['dropoff_rate_baseline'] * 1.5:
        alerts.append({
            "severity": "critical",
            "message": f"Drop-off rate spiked to {metrics['dropoff_rate']:.1%} (baseline: {metrics['dropoff_rate_baseline']:.1%})",
            "action": "Review journey logic and recent changes"
        })

    # Alert 2: Completion rate decline
    if metrics['completion_rate'] < metrics['completion_rate_baseline'] * 0.8:
        alerts.append({
            "severity": "warning",
            "message": f"Completion rate dropped to {metrics['completion_rate']:.1%}",
            "action": "A/B test new journey variations"
        })

    # Alert 3: AI decision point failure rate
    decision_error_rate = get_decision_error_rate(journey_id)
    if decision_error_rate > 0.05:  # >5% error rate
        alerts.append({
            "severity": "critical",
            "message": f"AI decision engine error rate: {decision_error_rate:.1%}",
            "action": "Check model performance and data quality"
        })

    # Send alerts
    if alerts:
        send_to_slack(channel="journey-alerts", alerts=alerts)
        send_to_pagerduty(alerts=[a for a in alerts if a['severity'] == 'critical'])

    return alerts
```

---

**Document Version**: 1.0
**Last Updated**: 2025-10-23
**Owner**: Marketing Automation & AI Team
**Next Review**: Monthly journey performance review
